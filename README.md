# lua-utf8-identifiers

This is a version of Lua that allows UTF-8 identifiers if `ALLOW_UTF8_IDENTIFIERS` is defined at compile time. Not all Unicode code points are allowed; the set of allowed code points more or less follows the rules given in [UnicodeÂ® Standard Annex #31: Unicode Identifier and Pattern Syntax &sect; Default Identifiers](https://www.unicode.org/reports/tr31/#Default_Identifier_Syntax).

In order to do this, bytes 0x80-0xFF are treated as alphabetic, so that the lexer puts them in a buffer along with the usual characters that vanilla Lua allows in identifiers. While putting them in the buffer, the lexer searches for bytes 0x80-0xFF. If such bytes were found, a function is called to step through the buffer, decoding byte sequences into code points and determining if the code points are allowed in an identifier. It determines this by binarily searching for the code points in arrays of ranges of code points. One array contains code points that are allowed throughout an identifier (like ASCII alphabetic characters and underscore in vanilla Lua), the other contains code points that are only allowed after the first code point in an identifier (like ASCII digits in vanilla Lua). If the identifier is not valid UTF-8 or contains a disallowed code point, an error is thrown at compile time.

A custom header that determines which characters are allowed in identifiers is generated by a Lua script from [UnicodeData.txt](https://www.unicode.org/Public/UNIDATA/UnicodeData.txt). The current version is based on Unicode 11.0.
